{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-28T17:15:29.759784Z","iopub.execute_input":"2022-04-28T17:15:29.760124Z","iopub.status.idle":"2022-04-28T17:15:29.798165Z","shell.execute_reply.started":"2022-04-28T17:15:29.760045Z","shell.execute_reply":"2022-04-28T17:15:29.797468Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nXtrain = np.load('../input/minimusicnet/audio-train.npy')\nYtrain = np.load('../input/minimusicnet/labels-train.npy')\n\nfig, ax = plt.subplots(1, 2, figsize=(10,2))\nax[0].set_title('Raw acoustic features')\nax[0].plot(Xtrain[0])\nax[1].set_title('Fourier transform of the raw features')\nax[1].plot(np.abs(np.fft.rfft(Xtrain[0])[0:256])) # clip to 256 features for easier visualization\n\n# https://github.com/prakashpandey9/Text-Classification-Pytorch/blob/master/load_data.py","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:29.799619Z","iopub.execute_input":"2022-04-28T17:15:29.799915Z","iopub.status.idle":"2022-04-28T17:15:43.930286Z","shell.execute_reply.started":"2022-04-28T17:15:29.799881Z","shell.execute_reply":"2022-04-28T17:15:43.929582Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import average_precision_score\n\n# Xtest = np.load('../input/minimusicnet/audio-test.npy')\n# Ytest = np.load('../input/minimusicnet/labels-test.npy')\n\n# R = .001\n# beta = np.dot(np.linalg.inv(np.dot(Xtrain.T,Xtrain) + R*np.eye(Xtrain.shape[1])),np.dot(Xtrain.T,Ytrain))\n\n# print('Train AP:', round(average_precision_score(Ytrain, np.dot(Xtrain, beta), average='micro'), 2))\n# print('Test AP:', round(average_precision_score(Ytest, np.dot(Xtest, beta), average='micro'), 2))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:43.931519Z","iopub.execute_input":"2022-04-28T17:15:43.931894Z","iopub.status.idle":"2022-04-28T17:15:43.935821Z","shell.execute_reply.started":"2022-04-28T17:15:43.931857Z","shell.execute_reply":"2022-04-28T17:15:43.935196Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Xtrainfft = np.abs(np.fft.rfft(Xtrain))\n# Xtestfft = np.abs(np.fft.rfft(Xtest))\n\n# R = .001\n# beta = np.dot(np.linalg.inv(np.dot(Xtrainfft.T,Xtrainfft) + R*np.eye(Xtrainfft.shape[1])),np.dot(Xtrainfft.T,Ytrain))\n\n# print('Train AP:', round(average_precision_score(Ytrain, np.dot(Xtrainfft, beta), average='micro'), 2))\n# print('Test AP:', round(average_precision_score(Ytest, np.dot(Xtestfft, beta), average='micro'), 2))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:43.937948Z","iopub.execute_input":"2022-04-28T17:15:43.938356Z","iopub.status.idle":"2022-04-28T17:15:43.945194Z","shell.execute_reply.started":"2022-04-28T17:15:43.938319Z","shell.execute_reply":"2022-04-28T17:15:43.944511Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport torch\nfrom torch.nn import functional as F\nimport numpy as np\nfrom torchtext import data\nfrom torchtext import datasets\nfrom torch.utils.data import Dataset\nimport torch.utils.data as data_utl\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom sklearn.metrics import average_precision_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\nXtrain = np.load('../input/minimusicnet/audio-train.npy')\nYtrain = np.load('../input/minimusicnet/labels-train.npy')\n\nXtest = np.load('../input/minimusicnet/audio-test.npy')\nYtest = np.load('../input/minimusicnet/labels-test.npy')\n\nYtrain, Ytest = Ytrain[:,21:-26], Ytest[:,21:-26]\n\nXtrainfft = np.abs(np.fft.rfft(Xtrain))\nXtestfft = np.abs(np.fft.rfft(Xtest))\n\n\nclass MiniMusicNetDataSet(Dataset):\n    \"\"\"MusicNet dataset.\"\"\"\n\n    def __init__(self, clips, labels):\n        \n        self.clips = clips\n        self.labels = labels\n\n    def __len__(self):\n        return self.clips.shape[0]\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        clip = torch.from_numpy(self.clips[idx]).float()\n        label = self.labels[idx]\n        sample = [clip, label]\n\n        return sample\n\nBATCH_SIZE = 64\nmax_freq_idx = 256 #clip the frequencies above 256Hz, as we don't have apreciable amplitude beyond that\n\nXtrainfft = Xtrainfft[:,:max_freq_idx]\nXtestfft = Xtestfft[:,:max_freq_idx]\n\ntrain_clips, train_labels = Xtrainfft[:50000], Ytrain[:50000]\nval_clips, val_labels = Xtrainfft[50000:], Ytrain[50000:]\ntest_clips, test_labels = Xtestfft, Ytest\n\ntrain_dataset = MiniMusicNetDataSet(train_clips, train_labels)\nval_dataset = MiniMusicNetDataSet(val_clips, val_labels)\ntest_dataset = MiniMusicNetDataSet(test_clips, test_labels)\n\nBATCH_SIZE = 32\ntrain_iterator = data_utl.DataLoader(train_dataset, \n                                 shuffle = True, \n                                 batch_size = BATCH_SIZE)\nval_iterator = data_utl.DataLoader(val_dataset, \n                                 shuffle = True, \n                                 batch_size = BATCH_SIZE)\ntest_iterator = data_utl.DataLoader(test_dataset, \n                                 shuffle = True, \n                                 batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:43.947863Z","iopub.execute_input":"2022-04-28T17:15:43.948062Z","iopub.status.idle":"2022-04-28T17:15:52.270365Z","shell.execute_reply.started":"2022-04-28T17:15:43.948037Z","shell.execute_reply":"2022-04-28T17:15:52.269595Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class LinearClassifier(nn.Module):\n    def __init__(self, seq_len, output_size):\n        super(LinearClassifier, self).__init__()\n        \n        self.seq_len = seq_len\n        self.output_size = output_size\n        self.dropout = nn.Dropout(0.5)\n        \n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(self.seq_len, 256),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.Linear(512, self.output_size)\n        )\n        \n\n    def forward(self, input_clips):\n        logits = self.linear_relu_stack(input_clips.squeeze(-1))\n        logits = self.dropout(logits)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:52.271810Z","iopub.execute_input":"2022-04-28T17:15:52.272062Z","iopub.status.idle":"2022-04-28T17:15:52.278072Z","shell.execute_reply.started":"2022-04-28T17:15:52.272030Z","shell.execute_reply":"2022-04-28T17:15:52.277436Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, batch_size, output_size, hidden_size):\n        super(LSTMClassifier, self).__init__()\n        \n        self.batch_size = batch_size\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.num_layers = 1\n        self.dirs = 1\n        self.dropout = 0.5\n        self.bidirectional = False\n        if self.bidirectional==True:\n            self.dirs = 2 # 1 for bidirectional=False, else 2\n        self.lstm = nn.LSTM(input_size=1, hidden_size= self.hidden_size, num_layers=self.num_layers, batch_first=True, bidirectional = self.bidirectional, dropout = self.dropout)\n        self.lin = nn.Linear(self.hidden_size, self.output_size)\n        self.sfmx = nn.Softmax(dim = 1)\n\n    def forward(self, input_clips):\n        h_0 = Variable(torch.zeros(self.num_layers*self.dirs, input_clips.shape[0], self.hidden_size).cuda())\n        c_0 = Variable(torch.zeros(self.num_layers*self.dirs, input_clips.shape[0], self.hidden_size).cuda())\n        output, (final_hidden_state, final_cell_state) = self.lstm(input_clips, (h_0, c_0))\n        final_output = self.lin(final_hidden_state[-1]) # final_hidden_state.size() = (1, batch_size, hidden_size) & final_output.size() = (batch_size, output_size)\n        final_output = self.sfmx(final_output)\n        return final_output","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:52.279311Z","iopub.execute_input":"2022-04-28T17:15:52.279695Z","iopub.status.idle":"2022-04-28T17:15:52.391990Z","shell.execute_reply.started":"2022-04-28T17:15:52.279661Z","shell.execute_reply":"2022-04-28T17:15:52.391130Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n# _*_ coding: utf-8 _*_\n\n\nclass AttentionModel(torch.nn.Module):\n    def __init__(self, batch_size, output_size, hidden_size):\n        super(AttentionModel, self).__init__()\n        self.batch_size = batch_size\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.num_layers = 1\n        self.dropout = 0.5\n        \n        self.dirs = 1\n        self.bidirectional = False\n        if self.bidirectional==True:\n            self.dirs = 2 # 1 for bidirectional=False, else 2\n\n        self.lstm = nn.LSTM(input_size=1, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True, bidirectional = self.bidirectional, dropout = self.dropout)\n        self.lin = nn.Linear(hidden_size, output_size)\n        self.lsfmx = nn.Softmax(dim = 1)\n        #self.attn_fc_layer = nn.Linear()\n        \n    def attention_net(self, lstm_output, final_state):\n\n        hidden = final_state.squeeze(0)\n        attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\n        soft_attn_weights = F.softmax(attn_weights, 1)\n        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n        return new_hidden_state\n\n    def forward(self, input_clips):\n\n        h_0 = Variable(torch.zeros(self.num_layers*self.dirs, input_clips.shape[0], self.hidden_size).cuda())\n        c_0 = Variable(torch.zeros(self.num_layers*self.dirs, input_clips.shape[0], self.hidden_size).cuda())\n\n        output, (final_hidden_state, final_cell_state) = self.lstm(input_clips, (h_0, c_0)) # final_hidden_state.size() = (1, batch_size, hidden_size) \n\n        attn_output = self.attention_net(output, final_hidden_state)\n        logits = self.lin(attn_output)\n#         logits = self.lsfmx(logits)\n\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:52.395555Z","iopub.execute_input":"2022-04-28T17:15:52.396178Z","iopub.status.idle":"2022-04-28T17:15:52.408884Z","shell.execute_reply.started":"2022-04-28T17:15:52.396150Z","shell.execute_reply":"2022-04-28T17:15:52.408179Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, batch_size, output_size, hidden_size):\n        super(SelfAttention, self).__init__()\n\n        self.batch_size = batch_size\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.dropout = 0.8\n        \n        self.dirs = 1\n        self.bidirectional = True\n        \n        if self.bidirectional==True:\n            self.dirs = 2 # 1 for bidirectional=False, else 2\n            \n        self.bilstm = nn.LSTM(input_size=1, \n                              hidden_size=self.hidden_size, \n                              batch_first=True, \n                              bidirectional = self.bidirectional, \n                              dropout=self.dropout)\n        # We will use da = 350, r = 30 & penalization_coeff = 1 as per given in the self-attention original ICLR paper\n        self.W_s1 = nn.Linear(2*self.hidden_size, 350)\n        self.W_s2 = nn.Linear(350, 30)\n        self.fc_layer = nn.Linear(30*2*hidden_size, 2000)\n        self.lin = nn.Linear(2000, output_size)\n\n    def attention_net(self, lstm_output):\n\n        attn_weight_matrix = self.W_s2(F.tanh(self.W_s1(lstm_output)))\n        attn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n        attn_weight_matrix = F.softmax(attn_weight_matrix, dim=2)\n\n        return attn_weight_matrix\n\n    def forward(self, input_clips):\n#         print(input_clips.shape)\n#         input_ = input_clips.permute(1, 0, 2)\n        h_0 = Variable(torch.zeros(2, input_clips.shape[0], self.hidden_size).cuda())\n        c_0 = Variable(torch.zeros(2, input_clips.shape[0], self.hidden_size).cuda())\n\n        output, (h_n, c_n) = self.bilstm(input_clips, (h_0, c_0))\n#         output = output.permute(1, 0, 2)\n        # output.size() = (batch_size, num_seq, 2*hidden_size)\n        # h_n.size() = (1, batch_size, hidden_size)\n        # c_n.size() = (1, batch_size, hidden_size)\n        attn_weight_matrix = self.attention_net(output)\n        # attn_weight_matrix.size() = (batch_size, r, num_seq)\n        # output.size() = (batch_size, num_seq, 2*hidden_size)\n        hidden_matrix = torch.bmm(attn_weight_matrix, output)\n        # hidden_matrix.size() = (batch_size, r, 2*hidden_size)\n        # Let's now concatenate the hidden_matrix and connect it to the fully connected layer.\n        fc_out = self.fc_layer(hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2]))\n        logits = self.lin(fc_out)\n        # logits.size() = (batch_size, output_size)\n\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:15:52.410856Z","iopub.execute_input":"2022-04-28T17:15:52.411363Z","iopub.status.idle":"2022-04-28T17:15:52.425391Z","shell.execute_reply.started":"2022-04-28T17:15:52.411328Z","shell.execute_reply":"2022-04-28T17:15:52.424698Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ConvClassifier2(nn.Module):\n    def __init__(self, batch_size, output_size, hidden_size):\n        super(ConvClassifier2, self).__init__()\n\n        self.batch_size = batch_size\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.dropout = 0\n\n        self.conv1 = nn.Conv1d(1,1,65,padding=32)\n        self.drop1 = nn.Dropout(self.dropout)\n        self.relu1 = nn.ReLU()\n\n        self.conv2 = nn.Conv1d(1,1,65,padding=32)\n        self.drop2 = nn.Dropout(self.dropout)\n        self.relu2 = nn.ReLU()\n\n        self.conv3 = nn.Conv1d(1,1,65,padding=32)\n        self.drop3 = nn.Dropout(self.dropout)\n        self.relu3 = nn.ReLU()\n\n        self.conv4 = nn.Conv1d(1,1,65,padding=32)\n        self.drop4 = nn.Dropout(self.dropout)\n        self.relu4 = nn.ReLU()\n\n        self.conv5 = nn.Conv1d(1,1,65,padding=32)\n        self.drop5 = nn.Dropout(self.dropout)\n        self.relu5 = nn.ReLU()\n\n        self.conv6 = nn.Conv1d(1,1,65,padding=32)\n        self.drop6 = nn.Dropout(self.dropout)\n        self.relu6 = nn.ReLU()\n\n        self.conv7 = nn.Conv1d(1,1,65,padding=32)\n        self.drop7 = nn.Dropout(self.dropout)\n        self.relu7 = nn.ReLU()\n\n        self.conv8 = nn.Conv1d(1,1,65,padding=32)\n        self.drop8 = nn.Dropout(self.dropout)\n        self.relu8 = nn.ReLU()\n\n        self.conv9 = nn.Conv1d(1,1,65,padding=32)\n        self.drop9 = nn.Dropout(self.dropout)\n        self.relu9 = nn.ReLU()\n\n        # self.conv10 = nn.Conv1d(1,1,65,padding=32)\n        # self.drop10 = nn.Dropout(self.dropout)\n        # self.relu10 = nn.ReLU()\n\n        self.lin = nn.Linear(256, self.output_size)\n\n\n\n    def forward(self, input_clips):\n        inter0 = input_clips.permute(0,2,1)\n        inter1 = self.relu1(self.drop1(self.conv1(inter0)))\n        inter2 = self.relu2(self.drop2(self.conv2(inter1)))\n        inter3 = self.relu3(self.drop3(self.conv3(inter2))) + inter0\n        inter4 = self.relu4(self.drop4(self.conv4(inter3)))\n        inter5 = self.relu5(self.drop5(self.conv5(inter4)))\n        inter6 = self.relu6(self.drop6(self.conv6(inter5))) + inter3\n        inter7 = self.relu7(self.drop7(self.conv7(inter6)))\n        inter8 = self.relu8(self.drop8(self.conv8(inter7)))\n        inter9 = self.relu9(self.drop9(self.conv9(inter8)))\n        # inter10 = self.relu10(self.drop10(self.conv10(inter9)))\n\n        final_output = self.lin(inter9).squeeze()\n        return final_output","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:19:41.440869Z","iopub.execute_input":"2022-04-28T19:19:41.441341Z","iopub.status.idle":"2022-04-28T19:19:41.457754Z","shell.execute_reply.started":"2022-04-28T19:19:41.441309Z","shell.execute_reply":"2022-04-28T19:19:41.457082Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class ConvClassifier3(nn.Module):\n    def __init__(self, batch_size, output_size, hidden_size):\n        super(ConvClassifier3, self).__init__()\n\n        self.batch_size = batch_size\n        self.output_size = output_size\n        self.hidden_size = hidden_size\n        self.dropout = 0.2\n\n        self.conv1 = nn.Conv1d(1,1,129,padding=64)\n        self.drop1 = nn.Dropout(self.dropout)\n        self.tanh = nn.Tanh()\n\n#         self.conv2 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop2 = nn.Dropout(self.dropout)\n\n#         self.conv3 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop3 = nn.Dropout(self.dropout)\n\n#         self.conv4 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop4 = nn.Dropout(self.dropout)\n        \n#         self.conv5 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop5 = nn.Dropout(self.dropout)\n\n#         self.conv6 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop6 = nn.Dropout(self.dropout)\n\n#         self.conv7 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop7 = nn.Dropout(self.dropout)\n\n#         self.conv8 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop8 = nn.Dropout(self.dropout)\n        \n#         self.conv9 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop9 = nn.Dropout(self.dropout)\n        \n#         self.conv10 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop10 = nn.Dropout(self.dropout)\n        \n#         self.conv11 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop11 = nn.Dropout(self.dropout)\n        \n#         self.conv12 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop12 = nn.Dropout(self.dropout)\n        \n#         self.conv13 = nn.Conv1d(1,1,129,padding=64)\n#         self.drop13 = nn.Dropout(self.dropout)\n\n        # self.conv10 = nn.Conv1d(1,1,65,padding=32)\n        # self.drop10 = nn.Dropout(self.dropout)\n        # self.relu10 = nn.ReLU()\n\n        self.lin = nn.Linear(256, self.output_size)\n\n        \n    def forward(self, input_clips):\n        inter0 = input_clips.permute(0,2,1)\n        inter1 = self.tanh(self.drop1(self.conv1(inter0)))\n#         inter2 = self.tanh(self.drop2(self.conv2(inter1))) \n#         inter3 = self.tanh(self.drop3(self.conv3(inter2))) + inter0\n#         inter4 = self.tanh(self.drop4(self.conv4(inter3)))\n#         inter5 = self.tanh(self.drop4(self.conv4(inter4)))\n#         inter6 = self.tanh(self.drop4(self.conv4(inter5)))\n#         inter7 = self.tanh(self.drop4(self.conv4(inter6))) + inter3\n#         inter8 = self.tanh(self.drop4(self.conv4(inter7)))\n#         inter9 = self.tanh(self.drop4(self.conv4(inter8)))\n#         inter10 = self.tanh(self.drop4(self.conv4(inter9)))\n#         inter11 = self.tanh(self.drop4(self.conv4(inter10))) + inter6 + inter3 + inter0\n#         inter12 = self.tanh(self.drop4(self.conv4(inter11)))\n#         inter13 = self.tanh(self.drop4(self.conv4(inter12)))\n#         inter14 = self.tanh(self.drop4(self.conv4(inter12)))\n\n        # inter10 = self.relu10(self.drop10(self.conv10(inter9)))\n\n        final_output = self.lin(inter1).squeeze()\n        return final_output","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:24:53.497569Z","iopub.status.idle":"2022-04-28T19:24:53.498395Z","shell.execute_reply.started":"2022-04-28T19:24:53.498148Z","shell.execute_reply":"2022-04-28T19:24:53.498172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn as nn\n\n\ndef clip_gradient(model, clip_value):\n    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n    for p in params:\n        p.grad.data.clamp_(-clip_value, clip_value)\n    \ndef train_model(model, train_iter, epoch):\n    total_epoch_loss = 0\n    total_epoch_psc = 0\n    model.cuda()\n    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n    steps = 0\n    model.train()\n    for idx, batch in enumerate(train_iter):\n        clip = batch[0].unsqueeze(-1)\n        target = batch[1]\n        target = torch.autograd.Variable(target).long()\n        if torch.cuda.is_available():\n            clip = clip.cuda()\n            target = target.cuda()\n        \n        optim.zero_grad()\n        prediction = model(clip)\n        loss = loss_fn(prediction, target.float())\n#         num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n#         acc = 100.0 * num_corrects/len(batch)\n        loss.backward()\n#         clip_gradient(model, 1e-1)\n        optim.step()\n        steps += 1\n        acc_dum = 0\n        avgp = average_precision_score(batch[1].detach().cpu().numpy().flatten(), prediction.detach().cpu().numpy().flatten(), average = 'weighted')\n        if steps % 100 == 0:\n            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Precision Score: {avgp: .2f}%')\n        \n        total_epoch_loss += loss.item()\n        total_epoch_psc += avgp\n        \n    return total_epoch_loss/len(train_iter), total_epoch_psc/len(train_iter)\n\ndef eval_model(model, val_iter):\n    total_epoch_loss = 0\n    total_epoch_psc = 0\n    model.eval()\n    with torch.no_grad():\n        for idx, batch in enumerate(val_iter):\n            clip = batch[0].unsqueeze(-1)\n            target = batch[1]\n            target = torch.autograd.Variable(target).long()\n            if torch.cuda.is_available():\n                clip = clip.cuda()\n                target = target.cuda()\n            prediction = model(clip)\n            loss = loss_fn(prediction, target.float())\n            avgp = average_precision_score(batch[1].detach().cpu().numpy().flatten(), prediction.detach().cpu().numpy().flatten(), average = 'weighted')\n            total_epoch_loss += loss.item()\n            total_epoch_psc += avgp\n\n    return total_epoch_loss/len(val_iter), total_epoch_psc/len(val_iter)\n\n\nlearning_rate = 1e-3\nbatch_size = 32\noutput_size = 81\nhidden_size = 1024\nEPOCHS = 15\n\nloss_fn = nn.BCEWithLogitsLoss()\n\n# model = LinearClassifier(max_freq_idx, output_size)\n\n# model = LSTMClassifier(batch_size, output_size, hidden_size)\n# model = AttentionModel(batch_size, output_size, hidden_size)\n# model = SelfAttention(batch_size, output_size, hidden_size)\nmodel = ConvClassifier3(batch_size, output_size, hidden_size)\n\ntl = []\ntp = []\nvl = []\nvp = []\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train_model(model, train_iterator, epoch)\n    val_loss, val_acc = eval_model(model, val_iterator)\n    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train AvgPrScore: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val AvgPrScore: {val_acc:.2f}%')\n    \n    tl.append(train_loss)\n    tp.append(train_acc)\n    vl.append(val_loss)\n    vp.append(val_acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:25:35.842350Z","iopub.execute_input":"2022-04-28T19:25:35.842679Z","iopub.status.idle":"2022-04-28T19:27:00.418696Z","shell.execute_reply.started":"2022-04-28T19:25:35.842638Z","shell.execute_reply":"2022-04-28T19:27:00.417974Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Plot avg precision\nplt.plot(tp)\nplt.plot(vp)\nplt.title('1-Layer Conv: Precision')\n# plt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'], loc='lower right')\nplt.show()\nplt.savefig('conv_1layer_precision')\n\n# Plot loss\nplt.plot(tl)\nplt.plot(vl)\nplt.title('1-Layer Conv: Loss')\n# plt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()\nplt.savefig('conv_1layer_loss')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:36:02.300144Z","iopub.execute_input":"2022-04-28T19:36:02.300858Z","iopub.status.idle":"2022-04-28T19:36:02.691817Z","shell.execute_reply.started":"2022-04-28T19:36:02.300820Z","shell.execute_reply":"2022-04-28T19:36:02.691146Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"import scipy\nfrom sklearn.metrics import accuracy_score\n\ntorch.cuda.empty_cache() \nclips = train_clips[:10000]\ntargets = train_labels[:10000]\n\nmodel.eval()\nwith torch.no_grad():\n    if torch.cuda.is_available():\n        clips = torch.tensor(clips).cuda()\n        clips = clips.unsqueeze(-1).float()\n        targets = torch.tensor(targets).cuda()\n        predictions = model(clips)\nY_test = targets\n\ndef thr_to_accuracy(thr, Y_test, predictions):\n    return -accuracy_score(Y_test.detach().cpu().numpy(), np.array(predictions.detach().cpu().numpy() >thr, dtype=np.int))\n\nbest_thr = scipy.optimize.fmin(thr_to_accuracy, args=(Y_test, predictions), x0=0.5)\nprint(best_thr)\n\naccuracy_thr = accuracy_score(Y_test.detach().cpu().numpy(), np.array(predictions.detach().cpu().numpy() >best_thr, dtype=np.int))\nprint(accuracy_thr)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:20:48.364316Z","iopub.status.idle":"2022-04-28T17:20:48.365319Z","shell.execute_reply.started":"2022-04-28T17:20:48.365057Z","shell.execute_reply":"2022-04-28T17:20:48.365084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache() \nclips = test_clips\ntargets = test_labels\n\nmodel.eval()\nwith torch.no_grad():\n    if torch.cuda.is_available():\n        clips = torch.tensor(clips).cuda()\n        clips = clips.unsqueeze(-1).float()\n        targets = torch.tensor(targets).cuda()\n        predictions = model(clips)\nY_test = targets\n\nt = 400\npred = np.array(predictions.detach().cpu().numpy() >best_thr[0], dtype=np.int)\nactual = targets.detach().cpu().numpy()\nprint(\"Actual note indices: {}\".format(np.where(actual[t]==1)[0]))\nprint(\"Predicted note indices: {}\".format(np.where(pred[t]==1)[0]))\nf,ax = plt.subplots(1,2)\nax[0].plot(pred[t])\nax[1].plot(actual[t])\nf,ax = plt.subplots(1,2)\nax[0].plot(np.sum(pred, axis = 0))\nax[1].plot(np.sum(actual, axis = 0))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:20:48.366661Z","iopub.status.idle":"2022-04-28T17:20:48.367062Z","shell.execute_reply.started":"2022-04-28T17:20:48.366836Z","shell.execute_reply":"2022-04-28T17:20:48.366860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Source: https://stackoverflow.com/questions/52093388/how-to-choose-optimal-threshold-for-class-probabilities\n\n# class proxyModel():\n#     def __init__(self, origin_model):\n#         self.origin_model = origin_model\n\n#     def predict_proba(self, ori_proba, threshold_list=None):\n#         # get origin probability\n# #         ori_proba = self.origin_model.predict_proba(x)\n# #         ori_proba = self.origin_model(x).detach().cpu().numpy()\n        \n\n#         # set default threshold\n#         if threshold_list is None:\n#             threshold_list = np.full(ori_proba[0].shape, 1)\n        \n#         # get the output shape of threshold_list\n#         output_shape = np.array(threshold_list).shape\n\n#         # element-wise divide by the threshold of each classes\n#         new_proba = np.divide(ori_proba, threshold_list)\n\n#         # calculate the norm (sum of new probability of each classes)\n#         norm = np.linalg.norm(new_proba, ord=1, axis=1)\n\n#         # reshape the norm\n#         norm = np.broadcast_to(np.array([norm]).T, (norm.shape[0],output_shape[0]))\n\n#         # renormalize the new probability\n#         new_proba = np.divide(new_proba, norm)\n\n#         return new_proba\n\n#     def predict(self, x, threshold_list=None):\n#         preds = np.argmax(self.predict_proba(x, threshold_list), axis=1)\n#         return preds\n\n# def scoreFunc(model, pred_prob, y_true, threshold_list):\n# #     y_pred = model.predict(X, threshold_list=threshold_list)\n#     y_pred_proba = model.predict_proba(pred_prob, threshold_list=threshold_list)\n\n#     ###### metrics ######\n#     from sklearn.metrics import accuracy_score\n#     from sklearn.metrics import roc_auc_score\n#     from sklearn.metrics import average_precision_score\n#     from sklearn.metrics import f1_score\n\n#     y_true = y_true.detach().cpu().numpy()\n# #     accuracy = accuracy_score(y_true, y_pred)\n# #     roc_auc = roc_auc_score(y_true, y_pred_proba, average='macro')\n# #     print(y_true.dtype())\n#     pr_auc = average_precision_score(y_true, y_pred_proba, average='macro')\n# #     f1_value = f1_score(y_true, y_pred, average='macro')\n#     return pr_auc\n\n# def weighted_score_with_threshold(threshold, model, pred_prob, Y_test, metrics='accuracy', delta=5e-5):\n#     # if the sum of thresholds were not between 1+delta and 1-delta, \n#     # return infinity (just for reduce the search space of the minimizaiton algorithm, \n#     # because the sum of thresholds should be as close to 1 as possible).\n# #     print(threshold)\n#     threshold_sum = np.sum(threshold)\n# #     print(threshold_sum)\n# #     print(threshold)\n\n#     if threshold_sum > 1+delta:\n#         return np.inf\n\n#     if threshold_sum < 1-delta:\n#         return np.inf\n\n#     # to avoid objective function jump into nan solution\n#     if np.isnan(threshold_sum):\n#         print(\"threshold_sum is nan\")\n#         return np.inf\n\n#     # renormalize: the sum of threshold should be 1\n#     normalized_threshold = threshold/threshold_sum\n\n#     # calculate scores based on thresholds\n#     # suppose it'll return 4 scores in a tuple: (accuracy, roc_auc, pr_auc, f1)\n#     scores = scoreFunc(model, pred_prob, Y_test, threshold_list=normalized_threshold)\n# #     print(scores)\n\n# #     scores = np.array(scores)\n# #     weight = np.array([1])\n\n# #     Give the metric you want to maximize a bigger weight:\n# #     if metrics == 'accuracy':\n# #         weight = np.array([10,1,1,1])\n# #     if metrics == 'roc_auc':\n# #         weight = np.array([10,1])\n# #     elif metrics == 'pr_auc':\n# #         weight = np.array([1,10])\n# #     elif metrics == 'f1':\n# #         weight = np.array([1,1,1,10])\n# #     elif 'all':\n# #         weight = np.array([1,1,1,1])\n\n# #     return negatitive weighted sum (because you want to maximize the sum, \n# #     it's equivalent to minimize the negative sum)\n# #     return -np.dot(weight, scores)\n# #     print(\"***\")\n# #     print(scores)\n#     return -scores\n\n\n# from scipy import optimize\n\n# #############################\n# torch.cuda.empty_cache() \n# clips = train_clips[:10000]\n# targets = train_labels[:10000]\n\n# model.eval()\n# with torch.no_grad():\n#     if torch.cuda.is_available():\n#         clips = torch.tensor(clips).cuda()\n#         clips = clips.unsqueeze(-1).float()\n#         targets = torch.tensor(targets).cuda()\n#         predictions = model(clips)\n#         preds_sfmx = nn.Softmax(dim=1)(predictions)\n#         print(predictions.shape)\n# #############################\n# pred_prob = preds_sfmx.detach().cpu().numpy()\n# assert np.sum(pred_prob[0])==1\n# Y_test = targets\n\n# output_class_num = targets.shape[1]\n# bounds = optimize.Bounds([1e-5]*output_class_num,[1]*output_class_num)\n# # bounds = [(1e-5,1)]*output_class_num\n# # print(bounds)\n\n# pmodel = proxyModel(model)\n# # print(pmodel.predict_proba(X_test))\n\n# def constr_f(threshold):\n#     return np.sum(threshold)\n\n# nlc = optimize.NonlinearConstraint(constr_f, 1-5e-5, 1+5e-5)\n\n# result = optimize.differential_evolution(weighted_score_with_threshold, bounds = bounds, args=(pmodel, pred_prob, Y_test, 'pr_auc'), disp = True, constraints=(nlc), maxiter=20)\n\n# # # calculate threshold\n# threshold = result.x/np.sum(result.x)\n# print(threshold)\n\n# # # print the optimized score\n# # print(scoreFunc(pmodel, pred_prob, Y_test, threshold_list=threshold))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:20:48.368555Z","iopub.status.idle":"2022-04-28T17:20:48.369156Z","shell.execute_reply.started":"2022-04-28T17:20:48.368911Z","shell.execute_reply":"2022-04-28T17:20:48.368937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from scipy.optimize import NonlinearConstraint, Bounds, rosen\n# def constr_f(y):\n#     return np.sum(y)\n\n# # the sum of x[0] and x[1] must be less than 1.9\n# nlc = NonlinearConstraint(constr_f, -np.inf, 5)\n# # specify limits using a `Bounds` object.\n# bounds = Bounds([0., 0.], [2., 2.])\n# result = optimize.differential_evolution(rosen, bounds, constraints=(nlc),\n#                                 seed=1)\n# result.x","metadata":{"execution":{"iopub.status.busy":"2022-04-28T17:20:48.370079Z","iopub.status.idle":"2022-04-28T17:20:48.370858Z","shell.execute_reply.started":"2022-04-28T17:20:48.370614Z","shell.execute_reply":"2022-04-28T17:20:48.370639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}